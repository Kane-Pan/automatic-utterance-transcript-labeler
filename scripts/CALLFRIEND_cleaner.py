import os
from pathlib import Path
import requests
import pandas as pd
from tqdm import tqdm

BASE_DIR = Path(__file__).resolve().parent.parent
INPUT_FILE = BASE_DIR / "data" / "CALLFRIEND_cleaned_2.csv"
OUTPUT_FILE = BASE_DIR / "results" / "CALLFRIEND_cleaned_2.csv"

API = "http://localhost:11434/api/generate"
LLM_MODEL = "mistral:instruct"
DEFAULT_MAX_TOK = 64
DEFAULT_TEMP = 0.0

# prompt generated by chat gpt
def build_clean_prompt(raw_utt: str) -> str:
    return f"""You are cleaning one line of a conversational transcript.

The line may contain many non-speech symbols and markup, such as:
- "hhh", "hh", "∙hhh" (breathing/laughter)
- "+≈", "+/", arrows "→"
- special brackets "⌈ ⌉ ⌊ ⌋"
- tags like [!], [NOISE], [UNINTELLIGIBLE]
- colons in the middle of words used for lengthening (e.g. "yea:h", "gu::ys::")

Your task:
1. Infer what the original spoken sentence probably was.
2. Ignore all non-speech symbols and markup listed above.
3. Write the sentence in natural, informal English.
4. Keep the words and their order as close as possible to the original (minimal paraphrasing).
5. If there are no real words (only noise like "hhh", breathing, or pure symbols), output exactly:
[UNINTELLIGIBLE]

Output rules (VERY IMPORTANT):
- Output ONLY the cleaned sentence or [UNINTELLIGIBLE].
- Do NOT include any explanations or commentary.
- Do NOT mention "original utterance", "cleaned utterance", "translation", etc.
- Do NOT add labels.
- Do NOT wrap the sentence in quotes.
- Do NOT output multiple lines.

Examples:

Noisy: "∙hhh they had this: little sce:ne where the gu::ys::→"
Clean: they had this little scene where the guys.

Noisy: "+≈ h:e, well he used to work for them yea:h → ⌈∙hhh (.) ∙hhh⌉→"
Clean: he, well, he used to work for them, yeah.

Noisy: "hhh hhh hhh hhh→"
Clean: [UNINTELLIGIBLE]

Now clean this line:
{raw_utt}
"""



def ask_llm_clean(utterance: str) -> str:
    prompt = build_clean_prompt(utterance)

    try:
        r = requests.post(
            API,
            json={
                "model": LLM_MODEL,
                "prompt": prompt,
                "temperature": DEFAULT_TEMP,
                "max_tokens": DEFAULT_MAX_TOK,
                "stream": False,
            },
            timeout=60,
        )
        r.raise_for_status()
        body = r.json().get("response", "").strip()

        if not body:
            return utterance
        return body
    except Exception:

        return utterance


def run_callhome_normalization():
    df = pd.read_csv(INPUT_FILE)

    if "utterance" not in df.columns:
        raise ValueError("Input CSV must have an 'utterance' column.")

    cleaned_utts = []

    for raw in tqdm(df["utterance"], desc="Normalizing CALLHOME utterances"):
        raw_str = "" if pd.isna(raw) else str(raw)
        cleaned = ask_llm_clean(raw_str)
        cleaned_utts.append(cleaned)

    # Overwrite the existing utterance column
    df["utterance"] = cleaned_utts

    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(OUTPUT_FILE, index=False)

    print(f"Wrote normalized CALLHOME transcript to {OUTPUT_FILE} "
          f"({len(df)} rows)")


if __name__ == "__main__":
    run_callhome_normalization()
